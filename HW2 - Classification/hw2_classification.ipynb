{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW2_Classification_FeatureEngineering.ipynb","provenance":[],"authorship_tag":"ABX9TyMiZhOEw4cma7dZM9pqSczr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"66be9bc26c344899b3455d7973ac0deb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa4bf85722e947e28b410af2b0f7907e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30a6ada8d6b64b1499cf3dcac409d586","IPY_MODEL_129b9c7933274e2b827c9f7c411a49f6"]}},"aa4bf85722e947e28b410af2b0f7907e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30a6ada8d6b64b1499cf3dcac409d586":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ccaaec38e6f477fb7fb6d07ca4a78a4","_dom_classes":[],"description":" 67%","_model_name":"FloatProgressModel","bar_style":"danger","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a223a05a8084a77a667f50f9fcb2cca"}},"129b9c7933274e2b827c9f7c411a49f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba03388315b04cb1b2c8376814c00e44","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/3 [06:46&lt;02:26, 146.14s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f36c3c799a64cd7ae094b525cc6d617"}},"9ccaaec38e6f477fb7fb6d07ca4a78a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2a223a05a8084a77a667f50f9fcb2cca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba03388315b04cb1b2c8376814c00e44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5f36c3c799a64cd7ae094b525cc6d617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e7ab69120264fbcbce8c3df9b000833":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a928b49ee554f198c749e31979ade39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d3d4d1e7f3f642378f54491a884d3836","IPY_MODEL_b2645834949544688aa4708f7545d784"]}},"0a928b49ee554f198c749e31979ade39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3d4d1e7f3f642378f54491a884d3836":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9140b1d4bd5140e88325540dfd9a402e","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":200,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":200,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b3460acb0f8b4657913a68dfd85649e7"}},"b2645834949544688aa4708f7545d784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b6d8ad30a719430c8f73ca1a61b9325e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 200/200 [04:24&lt;00:00,  1.32s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f75cbcb9a2e4d848a186dfd057d0f5b"}},"9140b1d4bd5140e88325540dfd9a402e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b3460acb0f8b4657913a68dfd85649e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6d8ad30a719430c8f73ca1a61b9325e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2f75cbcb9a2e4d848a186dfd057d0f5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d6ca2f04ccd44bbbc9db229fb6a004b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6556be42c48e4b1f87cb5ff2c11ac963","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5827d76c66a5434f812ef29322faddc1","IPY_MODEL_fb2fbbfa23724b5dbfdd5dc3766345e4"]}},"6556be42c48e4b1f87cb5ff2c11ac963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5827d76c66a5434f812ef29322faddc1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b02beb6e59884717875a4b8749dc280c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":200,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":200,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c81b3bd3190d461e92bdfbd010c88ba5"}},"fb2fbbfa23724b5dbfdd5dc3766345e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e5f6918b3bf4b95b3e00acc6bd034fe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 200/200 [02:07&lt;00:00,  1.57it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2018a7f11b24dbdbc8d6b3458eb0e2c"}},"b02beb6e59884717875a4b8749dc280c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c81b3bd3190d461e92bdfbd010c88ba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e5f6918b3bf4b95b3e00acc6bd034fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b2018a7f11b24dbdbc8d6b3458eb0e2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50de4a6aca1249ccb1eb56580b3a1fc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_af7fdf68dd8041bf9eb292af82c15d90","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85942c7dd1584e5fb0c0a9ef2288587e","IPY_MODEL_e4194719bc5a4a7f9e2acbd0c674fc80"]}},"af7fdf68dd8041bf9eb292af82c15d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85942c7dd1584e5fb0c0a9ef2288587e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_73cb8b8470404198afe72f0319e81bea","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":200,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":200,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acf1711b7df44311b634ecc471dfee3f"}},"e4194719bc5a4a7f9e2acbd0c674fc80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8557aae00e984dceb87566b5e335ae52","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 200/200 [15:02&lt;00:00,  4.51s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf15acf89fcf40939d8097a3e64b6f4b"}},"73cb8b8470404198afe72f0319e81bea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acf1711b7df44311b634ecc471dfee3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8557aae00e984dceb87566b5e335ae52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cf15acf89fcf40939d8097a3e64b6f4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GWf0oehbrlG8","colab_type":"text"},"source":["Optimize the Logisit Regression Model using\n","\n","1. Initialize weight using uniform random method\n","\n","2. Implement adagrad so that weight decay as epoh increase\n","\n","3. Implement L2 regulization\n"]},{"cell_type":"markdown","metadata":{"id":"4DWOvivN3jFS","colab_type":"text"},"source":["Ensemble Generative Model with Logistic Model"]},{"cell_type":"markdown","metadata":{"id":"yk8zjKSXro-S","colab_type":"text"},"source":["Result: \n","\n","Private Score: 0.89095\n","\n","Public Score: 0.88914\n","![替代文字](https://drive.google.com/uc?id=1h3NnRiUkG7Nve7klqFEnGt8qepvuTsM9)"]},{"cell_type":"markdown","metadata":{"id":"E5uoh25Zrpay","colab_type":"text"},"source":["Ranked: 104/285\n","\n","![替代文字](https://drive.google.com/uc?id=15KsiibD4Wb4xewFNtRx-REG1O1FFP4od)"]},{"cell_type":"markdown","metadata":{"id":"b1QNw4pRlqiY","colab_type":"text"},"source":["Dataset"]},{"cell_type":"code","metadata":{"id":"oW7fgDwWlSFe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1596513018118,"user_tz":-480,"elapsed":9308,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}},"outputId":"c603fc1d-50cb-43bf-f53b-5e814442da52"},"source":["!gdown --id '1KSFIRh0-_Vr7SdiSCZP1ItV7bXPxMD92' --output data.tar.gz\n","!tar -zxvf data.tar.gz\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1KSFIRh0-_Vr7SdiSCZP1ItV7bXPxMD92\n","To: /content/data.tar.gz\n","\r0.00B [00:00, ?B/s]\r6.11MB [00:00, 95.7MB/s]\n","data/\n","data/sample_submission.csv\n","data/test_no_label.csv\n","data/train.csv\n","data/X_test\n","data/X_train\n","data/Y_train\n","data  data.tar.gz  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xxeQV8uulvon","colab_type":"text"},"source":["Preparing Data"]},{"cell_type":"code","metadata":{"id":"Rd7q7gajlx1A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596534275364,"user_tz":-480,"elapsed":10625,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}},"outputId":"38f43a60-9eb0-4bf5-dc77-6664c7085506"},"source":["import numpy as np\n","\n","np.random.seed(0)\n","X_train_fpath = './data/X_train'\n","Y_train_fpath = './data/Y_train'\n","X_test_fpath = './data/X_test'\n","output_fpath = './output_{}.csv'\n","\n","# Parse csv files to numpy array\n","with open(X_train_fpath) as f:\n","    next(f)\n","    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n","with open(Y_train_fpath) as f:\n","    next(f)\n","    Y_train = np.array([line.strip('\\n').split(',')[1] for line in f], dtype = float)\n","with open(X_test_fpath) as f:\n","    next(f)\n","    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n","\n","def _normalize(X, train = True, specified_column = None, X_mean = None, X_std = None):\n","    # This function normalizes specific columns of X.\n","    # The mean and standard variance of training data will be reused when processing testing data.\n","    #\n","    # Arguments:\n","    #     X: data to be processed\n","    #     train: 'True' when processing training data, 'False' for testing data\n","    #     specific_column: indexes of the columns that will be normalized. If 'None', all columns\n","    #         will be normalized.\n","    #     X_mean: mean value of training data, used when train = 'False'\n","    #     X_std: standard deviation of training data, used when train = 'False'\n","    # Outputs:\n","    #     X: normalized data\n","    #     X_mean: computed mean value of training data\n","    #     X_std: computed standard deviation of training data\n","\n","    if specified_column == None:\n","        specified_column = np.arange(X.shape[1])\n","    if train:\n","        X_mean = np.mean(X[:, specified_column] ,0).reshape(1, -1)\n","        X_std  = np.std(X[:, specified_column], 0).reshape(1, -1)\n","\n","    X[:,specified_column] = (X[:, specified_column] - X_mean) / (X_std + 1e-8)\n","     \n","    return X, X_mean, X_std\n","\n","def _train_dev_split(X, Y, dev_ratio = 0.25):\n","    # This function spilts data into training set and development set.\n","    train_size = int(len(X) * (1 - dev_ratio))\n","    return X[:train_size], Y[:train_size], X[train_size:], Y[train_size:]\n","\n","def _train_dev_split_inverse(X, Y, dev_ratio = 0.25):\n","    # This function spilts data into training set and development set.\n","    train_size = int(len(X) * (1 - dev_ratio))\n","    return X[train_size:], Y[train_size:], X[:train_size], Y[:train_size]\n","\n","# Normalize training and testing data\n","X_train, X_mean, X_std = _normalize(X_train, train = True)\n","X_test, _, _= _normalize(X_test, train = False, specified_column = None, X_mean = X_mean, X_std = X_std)\n","\n","with open(X_test_fpath) as f:\n","  content = f.readline().strip('\\n').split(',')\n","features = np.array(content)\n","\n","train_size = X_train.shape[0]\n","test_size = X_test.shape[0]\n","data_dim = X_train.shape[1]\n","print('Size of training set: {}'.format(train_size))\n","print('Size of testing set: {}'.format(test_size))\n","print('Dimension of data: {}'.format(data_dim))"],"execution_count":120,"outputs":[{"output_type":"stream","text":["Size of training set: 54256\n","Size of testing set: 27622\n","Dimension of data: 510\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C81kd7Yel8yu","colab_type":"text"},"source":["Useful Function"]},{"cell_type":"code","metadata":{"id":"x_HaY_yBl6X-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596517845916,"user_tz":-480,"elapsed":894,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}}},"source":["def _shuffle(X, Y):\n","    # This function shuffles two equal-length list/array, X and Y, together.\n","    randomize = np.arange(len(X))\n","    np.random.shuffle(randomize)\n","    return (X[randomize], Y[randomize])\n","\n","def _sigmoid(z):\n","    # Sigmoid function can be used to calculate probability.\n","    # To avoid overflow, minimum/maximum output value is set.\n","    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\n","\n","def _f(X, w, b):\n","    # This is the logistic regression function, parameterized by w and b\n","    #\n","    # Arguements:\n","    #     X: input data, shape = [batch_size, data_dimension]\n","    #     w: weight vector, shape = [data_dimension, ]\n","    #     b: bias, scalar\n","    # Output:\n","    #     predicted probability of each row of X being positively labeled, shape = [batch_size, ]\n","    return _sigmoid(np.matmul(X, w) + b)\n","\n","def _predict(X, w, b):\n","    # This function returns a truth value prediction for each row of X \n","    # by rounding the result of logistic regression function.\n","    return np.round(_f(X, w, b)).astype(np.int)\n","\n","def _predict_prob(X, w, b):\n","    # This function returns a truth value prediction for each row of X \n","    # by rounding the result of logistic regression function.\n","    return _f(X, w, b)\n","    \n","def _accuracy(Y_pred, Y_label):\n","    # This function calculates prediction accuracy\n","    acc = 1 - np.mean(np.abs(Y_pred - Y_label))\n","    return acc\n","\n","def _cross_entropy_loss(y_pred, Y_label):\n","    # This function computes the cross entropy.\n","    #\n","    # Arguements:\n","    #     y_pred: probabilistic predictions, float vector\n","    #     Y_label: ground truth labels, bool vector\n","    # Output:\n","    #     cross entropy, scalar\n","    cross_entropy = -np.dot(Y_label, np.log(y_pred)) - np.dot((1 - Y_label), np.log(1 - y_pred))\n","    return cross_entropy\n","\n","def _gradient(X, Y_label, w, b):\n","    # This function computes the gradient of cross entropy loss with respect to weight w and bias b.\n","    y_pred = _f(X, w, b)\n","    pred_error = Y_label - y_pred\n","    w_grad = -np.sum(pred_error * X.T, 1)\n","    b_grad = -np.sum(pred_error)\n","    return w_grad, b_grad\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GS6cJp7w4RXd","colab_type":"text"},"source":["Generative Model Defination"]},{"cell_type":"code","metadata":{"id":"_Vze5i__4TYD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596532081973,"user_tz":-480,"elapsed":987,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}}},"source":["def Generative(X_train, Y_train):\n","\n","  # Compute in-class mean\n","  X_train_0 = np.array([x for x, y in zip(X_train, Y_train) if y == 0])\n","  X_train_1 = np.array([x for x, y in zip(X_train, Y_train) if y == 1])\n","\n","  mean_0 = np.mean(X_train_0, axis = 0)\n","  mean_1 = np.mean(X_train_1, axis = 0)  \n","\n","  # Compute in-class covariance\n","  cov_0 = np.zeros((data_dim, data_dim))\n","  cov_1 = np.zeros((data_dim, data_dim))\n","\n","  for x in X_train_0:\n","      cov_0 += np.dot(np.transpose([x - mean_0]), [x - mean_0]) / X_train_0.shape[0]\n","  for x in X_train_1:\n","      cov_1 += np.dot(np.transpose([x - mean_1]), [x - mean_1]) / X_train_1.shape[0]\n","\n","  # Shared covariance is taken as a weighted average of individual in-class covariance.\n","  cov = (cov_0 * X_train_0.shape[0] + cov_1 * X_train_1.shape[0]) / (X_train_0.shape[0] + X_train_1.shape[0])\n","\n","  # Compute inverse of covariance matrix.\n","  # Since covariance matrix may be nearly singular, np.linalg.inv() may give a large numerical error.\n","  # Via SVD decomposition, one can get matrix inverse efficiently and accurately.\n","  u, s, v = np.linalg.svd(cov, full_matrices=False)\n","  inv = np.matmul(v.T * 1 / s, u.T)\n","\n","  # Directly compute weights and bias\n","  w = np.dot(inv, mean_0 - mean_1)\n","  b =  (-0.5) * np.dot(mean_0, np.dot(inv, mean_0)) + 0.5 * np.dot(mean_1, np.dot(inv, mean_1))\\\n","      + np.log(float(X_train_0.shape[0]) / X_train_1.shape[0]) \n","\n","  # Compute accuracy on training set\n","  Y_train_pred = 1 - _predict(X_train, w, b)\n","  print('Training accuracy: {}'.format(_accuracy(Y_train_pred, Y_train)))\n","\n","\n","  return w, b"],"execution_count":101,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hEmvjbxu8Njw","colab_type":"text"},"source":["Logisit Regression Model Defination"]},{"cell_type":"code","metadata":{"id":"evVp9jxe6Bd0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596532085786,"user_tz":-480,"elapsed":1090,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}}},"source":["from tqdm.notebook import trange\n","\n","def LogisticRegression(X_train, Y_train):\n","\n","  data_dim = X_train.shape[1]\n","  #use uniform random to initialize weights\n","  w = np.random.uniform(0.01, -0.01, data_dim)\n","  b = np.zeros((1,))\n","\n","  # Some parameters for training    \n","  max_iter = 200\n","  batch_size = 32\n","  learning_rate = 0.02\n","\n","  # Keep the loss and accuracy at every iteration for plotting\n","  train_loss = []\n","  dev_loss = []\n","  train_acc = []\n","  dev_acc = []\n","\n","  eps = 0.0000001\n","  w_adagrad = np.zeros(data_dim)\n","  b_adagrad = 0\n","\n","  l2_regulization = 0.00001\n","\n","  epoh = 0\n","  early_stop = 0\n","  for epoh in trange(max_iter):\n","    # Random shuffle at the begging of each epoch\n","    X_train, Y_train = _shuffle(X_train, Y_train)\n","\n","    #mini-batch\n","    for idx in range(train_size//batch_size):\n","      X = X_train[idx*batch_size:(idx+1)*batch_size]\n","      Y = Y_train[idx*batch_size:(idx+1)*batch_size]\n","\n","      w_grad, b_grad = _gradient(X, Y, w, b)\n","      w_adagrad += w_grad ** 2\n","      b_adagrad += b_grad ** 2\n","\n","      w = w*(1-learning_rate*l2_regulization) - learning_rate/np.sqrt(w_adagrad+eps) * w_grad\n","      b = b*(1-learning_rate*l2_regulization) - learning_rate/np.sqrt(b_adagrad+eps) * b_grad\n","    # Compute loss and accuracy of training set and development set\n","    y_train_pred = _f(X_train, w, b)\n","    Y_train_pred = np.round(y_train_pred)\n","    train_acc.append(_accuracy(Y_train_pred, Y_train))\n","    train_loss.append(_cross_entropy_loss(y_train_pred, Y_train) / train_size)\n","\n","  print('Training loss: {}'.format(train_loss[-1]))\n","  print('Training accuracy: {}'.format(train_acc[-1]))\n","  logi_pred_prob = _predict_prob(X_test, w, b)\n","\n","  return train_acc[-1], w, b\n","  #return w for feature imortance calculation, remove last w that passed from generative model"],"execution_count":102,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0E8vORqs8UVR","colab_type":"text"},"source":["Append Generative Model Result to Training Set for Ensemble with Logisit Regression Model\n","\n","Then drop the unimportant features recursively and to find best number of features used"]},{"cell_type":"code","metadata":{"id":"8TH2JaHw63F3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451,"referenced_widgets":["66be9bc26c344899b3455d7973ac0deb","aa4bf85722e947e28b410af2b0f7907e","30a6ada8d6b64b1499cf3dcac409d586","129b9c7933274e2b827c9f7c411a49f6","9ccaaec38e6f477fb7fb6d07ca4a78a4","2a223a05a8084a77a667f50f9fcb2cca","ba03388315b04cb1b2c8376814c00e44","5f36c3c799a64cd7ae094b525cc6d617","7e7ab69120264fbcbce8c3df9b000833","0a928b49ee554f198c749e31979ade39","d3d4d1e7f3f642378f54491a884d3836","b2645834949544688aa4708f7545d784","9140b1d4bd5140e88325540dfd9a402e","b3460acb0f8b4657913a68dfd85649e7","b6d8ad30a719430c8f73ca1a61b9325e","2f75cbcb9a2e4d848a186dfd057d0f5b","2d6ca2f04ccd44bbbc9db229fb6a004b","6556be42c48e4b1f87cb5ff2c11ac963","5827d76c66a5434f812ef29322faddc1","fb2fbbfa23724b5dbfdd5dc3766345e4","b02beb6e59884717875a4b8749dc280c","c81b3bd3190d461e92bdfbd010c88ba5","7e5f6918b3bf4b95b3e00acc6bd034fe","b2018a7f11b24dbdbc8d6b3458eb0e2c","50de4a6aca1249ccb1eb56580b3a1fc3","af7fdf68dd8041bf9eb292af82c15d90","85942c7dd1584e5fb0c0a9ef2288587e","e4194719bc5a4a7f9e2acbd0c674fc80","73cb8b8470404198afe72f0319e81bea","acf1711b7df44311b634ecc471dfee3f","8557aae00e984dceb87566b5e335ae52","cf15acf89fcf40939d8097a3e64b6f4b"]},"executionInfo":{"status":"ok","timestamp":1596533438936,"user_tz":-480,"elapsed":411819,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}},"outputId":"199cebe3-64bd-4a64-96b8-9ebab45d2825"},"source":["n_remove = 100\n","\n","best_acc = 0\n","best_w = None\n","best_b = None\n","best_X_test = None\n","\n","iteration = 2\n","\n","for t in trange(iteration):\n","\n","  w, b = Generative(X_train, Y_train)\n","  gm_Y_train_pred_prob = 1 - _predict_prob(X_train, w, b)\n","  gm_Y_train_pred_prob = gm_Y_train_pred_prob.reshape(-1, 1)\n","  X_train = np.append(X_train, gm_Y_train_pred_prob, axis=1)\n","  \n","  gm_pred_prob = 1 - _predict_prob(X_test, w, b)\n","  gm_pred_prob = gm_pred_prob.reshape(-1, 1)\n","  X_test = np.append(X_test, gm_pred_prob, axis=1)\n","  \n","  #remove last n_remove\n","  \n","  acc, w, b = LogisticRegression(X_train, Y_train)\n","\n","  if acc > best_acc:\n","    best_acc = acc\n","    best_w = w\n","    best_X_test = X_test\n","    best_b = b\n","  \n","  if t == (iteration-1):\n","    break;\n","\n","  ind = np.argsort(np.abs(w))[::-1]\n","  drop = []\n","  for i in ind[-1:-n_remove:-1]:\n","    drop.append(i)\n","\n","  X_train = np.delete(X_train, drop, axis=1)\n","  X_test = np.delete(X_test, drop, axis=1)\n","  features = np.delete(features, drop, axis=0)\n","  #gm_Y_train_pred_prob = np.delete(gm_Y_train_pred_prob, drop, axis=1)\n","\n","  train_size = X_train.shape[0]\n","  test_size = X_test.shape[0]\n","  data_dim = X_train.shape[1]\n","  print('Size of training set: {}'.format(train_size))\n","  print('Size of testing set: {}'.format(test_size))\n","  print('Dimension of data: {}'.format(data_dim))"],"execution_count":116,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66be9bc26c344899b3455d7973ac0deb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Training accuracy: 0.8693232084930699\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e7ab69120264fbcbce8c3df9b000833","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Training loss: 0.26670946004648644\n","Training accuracy: 0.8858375110586848\n","Size of training set: 54256\n","Size of testing set: 27622\n","Dimension of data: 462\n","Training accuracy: 0.8752580359775878\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d6ca2f04ccd44bbbc9db229fb6a004b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Training loss: 0.26703420904325836\n","Training accuracy: 0.8856900619286346\n","Size of training set: 54256\n","Size of testing set: 27622\n","Dimension of data: 414\n","Training accuracy: 0.8772485992332645\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50de4a6aca1249ccb1eb56580b3a1fc3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Training loss: 0.26667576387250375\n","Training accuracy: 0.8856900619286346\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c0XT7La6NMEC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596534240384,"user_tz":-480,"elapsed":969,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}},"outputId":"e3c31d4a-1aaa-4804-e1c2-6162a1a44745"},"source":["best_acc"],"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8858375110586848"]},"metadata":{"tags":[]},"execution_count":119}]},{"cell_type":"code","metadata":{"id":"-WWQrRuxHkI-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596534206848,"user_tz":-480,"elapsed":1051,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}}},"source":["# Predict testing labels\n","#X_test, w, b = best_X_test, best_w, best_b\n","predictions = _predict(X_test, w, b)\n","with open(output_fpath.format('ensemble'), 'w') as f:\n","    f.write('id,label\\n')\n","    for i, label in  enumerate(predictions):\n","        f.write('{},{}\\n'.format(i, label))"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHvctUDwNV4Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596523480284,"user_tz":-480,"elapsed":103364,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}},"outputId":"6c513d64-122c-4f0c-c07e-4ad623b0ddf9"},"source":["!gdown --id 1VoF-D1FH0PhIne0pdDMKNmSg-SXfBoKS\n","!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/kaggle.json"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1VoF-D1FH0PhIne0pdDMKNmSg-SXfBoKS\n","To: /content/kaggle.json\n","\r  0% 0.00/65.0 [00:00<?, ?B/s]\r100% 65.0/65.0 [00:00<00:00, 125kB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZrfZsoJdNY0r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1596534216973,"user_tz":-480,"elapsed":8623,"user":{"displayName":"Ken Lin","photoUrl":"","userId":"10997747731961075639"}},"outputId":"11ab40b3-bd34-4583-c205-07dcc106e706"},"source":["!kaggle competitions submit -c ml2020spring-hw2 -f output_ensemble.csv -m \"Message\""],"execution_count":118,"outputs":[{"output_type":"stream","text":["Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","100% 205k/205k [00:04<00:00, 43.5kB/s]\n","Successfully submitted to ML2020spring - hw2"],"name":"stdout"}]}]}